
## Preceptor

Think about what to do with Introduction.



# Introductions

This package will hold all of our new breed AI tutorials.


## Plan for R4DS

We will have 5 one hour tutorials which cover the material in R4DS. It is tricky to figure out the best way to organize this since so many of the later tutorials cover stand-alone topics like spreadsheets and databases. Placing the chapters in order does not make a lot of sense. 

In essence, each of our five tutorials should start with a get-the-data section which makes use of one of the later chapters. It then also covers the material in some of the middle chapters. The intro chapters are all covered in the first tutorial.

We don't cover any of the workflow chapters, or chapters 27-29.


### r4ds-1

data import
data visualization
data transformations
data tidying


### r4ds-2

spreadsheets
layers
exploratory data analysis
communication

### r4ds-3

databases (duck)
logical vectors
numbers
strings
regular expressions

### r4ds-4

arrow
factors
dates-times
missing values
joins

### r4ds-5

hierarchical-data
web-scraping
functions
iterations

### R4DS tutorial structure

The introduction and summary are like any AI tutorial: Github, GH Pages and so on.

There are 3 to 5 Sections, each begins with some data processing and/or manipulation, questions which cover the important packages and functions in the relevant chapters. 

### Data storage

Most R4DS tutorials require the use of some strange data structures, like arrow files, spreadsheets and what not. We want to maintain our own copies of those starter files, even though they originally come from the web somewhere. 

* These are stored in the `data` directory of the tutorial in which they are used. 

* Document where these files come from in a brief note in `inst/extdata/README.txt`. (Maybe this should be elsewhere?) Or maybe there should be a .R script which recreates the files in that directory? Then, if you want to use the new ones, you move them over by hand to the relevant data directory.

* The files should be much less than 100 megabytes each because we want students to be able to easily download them and back them up in their personal repos.

* The big problem is that if we keep the datasets in the `data` directories, then we can't put the package on CRAN because it will be too big. Solution? Maybe we just keep all the data in extdata, then there is a script which downloads the files and puts them in the correct `data` directories. That script might be run by hand, sort of like the script which sets up tinytex. Appropriate checks would then need to be added to the tutorials so that they might report if the data is not there.


### Preceptor

* Finish skeleton in tutorial.helpers

* Create function for downloading data from extdata on GitHub and installing the relevant data in the correct data directory. Really want to put this package on CRAN!

* Finish "Tutorials in the Age of AI" in tutorial.helpers.

* Rewrite "Instructions"



