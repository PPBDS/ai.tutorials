---
title: A Fourth Tutorial for R4DS
author: Sruthi Gandhi and David Kane
tutorial:
  id: r4ds-4
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: 'This tutorial for "R for Data Science" covers Chapter 16: Factors, Chapter 17: Dates and Times, Chapter 18: Missing Values, Chapter 19: Joins, and Chapter 22: Arrow.'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(arrow)
library(dplyr)
library(lubridate)
library(forcats)
library(stringr)
library(tidyr)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- XX: CHECKLIST BEFORE STARTING: -->
<!-- * If you need to use the copy code button, you must load the relevant child document. -->
<!-- * Use check_current_tutorial() and make_exercise(). Very helpful! -->
<!-- * Edit yaml at the top of this file -->
<!-- * Save the file as "tutorial.Rmd" in the correct directory under inst/tutorials/. -->
<!-- * Load any necessary libraries for the tutorial in the first code chunk -->
<!-- * Anytime to have a student `Cmd/Ctrl + Enter`, you ask for CP/CR and then provide your code. -->
<!-- * Delete this and the other commented instructions below. -->

## Introduction
###

<!-- XX: Two to four sentence about the main packages/functions covered in this tutorial. -->

### Exercise 1

Create a Github repo called `r4ds-4`. Make sure to click the "Add a README file" check box.

Connect the repo to a project on your computer using `File -> New Folder from Git ...`.  Make sure to select the "Open in a new window" box. 

You need two Positon windows: this one for running the tutorial and the one you just created for writing your code and interacting with the Console.

In the new window, select `File -> New File -> Quarto Document ...`. Provide a title -- `"XX"` -- and an author (you). Render the document and save it as `analysis.qmd`.

Create a `.gitignore` file with `analysis_files` on the first line and then a blank line. Save and push.

In the Console, run:

```         
show_file(".gitignore")
```

If that fails, it is probably because you have not yet loaded `library(tutorial.helpers)` in the Console.

CP/CR.

```{r introduction-1}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 2

In your QMD, put `library(tidyverse)` in a new code chunk. Render the file using `Cmd/Ctrl + Shift + K`.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in this `setup` chunk. Also, add the following to the YAML header to remove all code echos from the HTML:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("analysis.qmd", chunk = "Last")
```

CP/CR.

```{r introduction-2}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 3

Place your cursor in the QMD file on the `library(tidyverse)` line. Use `Cmd/Ctrl + Enter` to execute that line.

Note that this causes `library(tidyverse)` to be copied down to the Console and then executed. 

CP/CR.

```{r introduction-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

###

<!-- XX: Insert a knowledge drop related to this project. -->


### Exercise 4

<!-- XX: Delete this question if you do not make use of the `data` directory in this tutorial. -->

From the Console, run these three commands:

`getwd()`
`dir.create("data")`
`list.files()`

This will create a `data` directory in your project. This is a good place to store any data that you are working with.

CP/CR

```{r introduction-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

You answer should look something like, although your path will be different.

````
> getwd()
[1] "/Users/dkane/Desktop/projects/XX"
> dir.create("data")
> list.files()
 [1] "analysis.qmd"        "data"    "README.md"
>
````

<!-- XX: You will probably have two or three Sections, in between the Introduction and Summary. We provide on example below. Before editing it, you may want to copy/paste it to create the skeleton for Second section. Any tutorial which both uses a lot of AI and is supppsed to take an hour or so will probably only have two Sections.  -->

## NBA Games
###

<!-- XX: Mention the packages/functions which you plan on covering in this Section. Not everything mentioned here is used in the Introduction/Summary, but everything in Introduction/Summary is referenced in one of these Section intro parts, the space before Exercise 1. -->

### Exercise 1

We begin by downloading our parquet files `data/game.parquet` and `line_score.parquet` directly from GitHub using `download.file()`. 

This adds the parquet files, `game.parquet` and `line_score.parquet`, to our working directory so we can use it in this tutorial.

In the Console, run:

```         
download.file(
  "https://github.com/PPBDS/ai.tutorials/raw/refs/heads/main/inst/tutorials/r4ds-4/data/game.parquet",
  destfile = "data/game.parquet"
)
download.file(
  "https://github.com/PPBDS/ai.tutorials/raw/refs/heads/main/inst/tutorials/r4ds-4/data/line_score.parquet",
  destfile = "data/line_score.parquet"
)
```

CP/CR.

```{r nba-games-1}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

<!-- SG: Insert knowledge drop.--> 

### Exercise 2

Ask AI to write R code that pipes the file `data/game.parquet` and opens the parquet file using `open_dataset()`. Make sure this code is not assigned to a variable and the pipe starts with `data/game.parquet`. Add this code to a new code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-2}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

Our code:

```{r nba-games-2-test, echo = TRUE}
"data/game.parquet" |> 
  open_dataset()
```

###

<!-- SG: Insert knowledge drop.--> 

### Exercise 3

Ask AI to write R code that continues our pipe that opened `data/game.parquet` and selects the columns `game_id`, `game_date`, and `season_id` columns, then collects it into R using `collect()`. After that, ask it to parse `game_date` as a datetime with `ymd_hms()`, extract the `year`, `month` (with labels), and `weekday` (with labels), and then count how many games occurred on each weekday, arranging the result in descending order using `desc()`. Add this code as a continuation of your current pipe in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

Our code:

```{r nba-games-3-test, echo = TRUE}
"data/game.parquet" |> 
  open_dataset()|>
  select(game_id, game_date, season_id) |>
  collect() |>
  mutate(
    # Parse the datetime string
    parsed_date = ymd_hms(game_date),
    # Extract year
    game_year = year(parsed_date),
    # Extract month with labels
    game_month = month(parsed_date, label = TRUE),
    # Get day of week with labels
    game_weekday = wday(parsed_date, label = TRUE)
  ) |>
  count(game_weekday) |>
  arrange(desc(n))
```

###

This tibble shows that the most amount of NBA games occur on Friday and Wedesday, while the least amount occurs on Monday. 

Dates-Times
Key Functions: ymd_hms(), year(), month(), wday()

<!-- SG: Insert knowledge drop.--> 

### Exercise 4

Paste our pipe into AI and ask AI to change our pipe so that it selects the columns for home and away stats (`reb_home, reb_away, fg3m_home, fg3m_away, stl_home, stl_away, blk_home, blk_away`), then calculates how many missing values each column has. Then, reshape the results with `pivot_longer()` into `column/missing_count` format, add a column for total rows (65,698) and missing percentage, and finally arrange in descending order of missing percentage. 

Add this code as a replacement to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-4-test, echo = TRUE}
"data/game.parquet" |> 
  open_dataset()|>
  collect() |>
  select(reb_home, reb_away, fg3m_home, fg3m_away, stl_home, stl_away, blk_home, blk_away) |>
  summarise_all(~sum(is.na(.))) |>
  pivot_longer(everything(), names_to = "column", values_to = "missing_count") |>
  mutate(
    total_games = 65698,  # total rows in dataset
    missing_pct = missing_count / total_games * 100
  ) |>
  arrange(desc(missing_pct))
```

###

On average, 25% of our data is missing from our selected columns of home and away rebounds, 3-pointers, and steals. 

is.na(), summarise_all(), sum()
pivot_longer

<!-- SG: Insert knowledge drop.--> 

### Exercise 5

Ask AI to write R code that changes our pipe so that it parses `game_date` with `ymd_hms()`, and creates a new variable called `decade` by flooring the year to the nearest decade, then filters out missing decades and groups by decade (using `group_by()`) and summarises the total number of games plus the percentage of missing values for `reb_home`, `fg3m_home`, and `stl_home`.  Make sure the AI uses `.groups` to drop the grouping at the end. 

Add this code as a replacement to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-5-test, echo = TRUE}
"data/game.parquet" |> 
  open_dataset()|>
  collect() |>
  mutate(
    game_date = ymd_hms(game_date),
    decade = 10 * (year(game_date) %/% 10)
  ) |>
  filter(!is.na(decade)) |>
  group_by(decade) |>
  summarise(
    total_games = n(),
    missing_rebounds_pct = sum(is.na(reb_home)) / n() * 100,
    missing_3pt_pct = sum(is.na(fg3m_home)) / n() * 100,
    missing_steals_pct = sum(is.na(stl_home)) / n() * 100,
    .groups = "drop"
  )
```

###

This helps us understand what data is reliable for different time periods.  The `missing_3pt_pct` column shows that data for 3-point shots before 1980 are 90 - 100% missing. This is because the 3-point line was not introduced in the NBA until the 1979 - 1980 season.

<!-- SG: Insert knowledge drop.--> 

### Exercise 6

Ask AI to write R code that changes our pipe and groups it by `team_name_home`, then calculates the average home points per team using `mean()` and `na.rm = TRUE`, sorts the results in descending order using `arrange(desc())`, selects the top 4 teams using `slice_head()`, and then reorders `team_name_home` as a factor by `avg_pts` for plotting using `fct_reorder`. Make sure the AI uses `.groups` to drop the grouping at the end. 

Add this code as a replacement to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-6}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-6-test, echo = TRUE}
"data/game.parquet" |> 
  open_dataset() |>
  collect() |>
  group_by(team_name_home) |>
  summarise(avg_pts = mean(pts_home, na.rm = TRUE), .groups = "drop") |>
  arrange(desc(avg_pts)) |>
  slice_head(n = 4) |>  # select top 10 teams
  mutate(team_name_home = fct_reorder(team_name_home, avg_pts))
```

###

The top four teams that have the highest points seem to be names of players and not actual NBA teams. This is because they are from NBA: All Stars where only star players compete, therefore skewing the data since a team of only star players will likely score more points during a game. This parquet file contains all kinds of NBA game data, not just the standard ones. 

<!-- SG: Insert knowledge drop.--> 

### Exercise 7

We are going to clean the data by converting date-time into useful components (`game_year`, `game_month`, `game_weekday`), simplifying team abbreviations (recoding old names and lumping less common ones), and creating a new variable `home_result` to indicate whether the home team won or lost.

Ask AI to write a single-pipe R workflow using `open_dataset()` and `collect()` to read the `line_score.parquet` file. Parse the `game_date_est` column into a date using `ymd_hms()` and `as_date()`, then extract `game_year`, `game_month` (with `label = TRUE`), and `game_weekday` (with `label = TRUE`). Convert `team_abbreviation_home` into a factor with `as_factor()` and rename levels using `fct_recode()` (e.g., `"PHW" = "Warriors"`, `"MNL" = "Lakers"`), then lump all but the top 8 teams with `fct_lump()`. Then create a `home_result` factor from `pts_home` vs `pts_away`.

Add this code as a replacement to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-7}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-7-test, echo = TRUE}
 open_dataset("data/line_score.parquet") |>
  collect() |>
  mutate(
    game_date = ymd_hms(game_date_est) |> as_date(),
    game_year = year(game_date),
    game_month = month(game_date, label = TRUE),
    game_weekday = wday(game_date, label = TRUE),
    team_abbreviation_home = as_factor(team_abbreviation_home) |>
      fct_recode(
        "Warriors" = "PHW",
        "Lakers" = "MNL"
      ) |>
      fct_lump(n = 8),
      home_result = factor(
      ifelse(pts_home > pts_away, "Win", "Loss"),
      levels = c("Win", "Loss")
    )
  )
```

###

<!-- SG: Insert knowledge drop.--> 

### Exercise 8

We are going to use the number of wins and points to determine if the game was considered a close win, a moderatley close win, or a absolute blowout win then count how many of each type of win occured in the early era of the NBA. 

Ask AI to continue our pipe from the last exercise and categorize `margin_category` based on the absolute point difference using `case_when()`, then order it with `factor()` and `fct_relevel()`. Create an `era` factor using `game_year` with `case_when()` and `fct_relevel()`. Compute `month_start` with `floor_date()`, `days_since_jan1` by subtracting `floor_date(game_date, "year")` from `game_date`, and `next_week` by adding `days(7)`. Finally, arrange the dataset by `game_date` with `arrange()`, limit to 1000 rows with `slice_head()`, and count games by `era` and `margin_category` using `count()`.

Add this code as a continuation to your current pipe in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-8-test, echo = TRUE}
 open_dataset("data/line_score.parquet") |>
  collect() |>
  mutate(
    game_date = ymd_hms(game_date_est) |> as_date(),
    game_year = year(game_date),
    game_month = month(game_date, label = TRUE),
    game_weekday = wday(game_date, label = TRUE),
    team_abbreviation_home = as_factor(team_abbreviation_home) |>
      fct_recode(
        "Warriors" = "PHW",
        "Lakers" = "MNL"
      ) |>
      fct_lump(n = 8),
      home_result = factor(
      ifelse(pts_home > pts_away, "Win", "Loss"),
      levels = c("Win", "Loss")
    ),
    margin_category = case_when(
      abs(pts_home - pts_away) <= 3 ~ "Close",
      abs(pts_home - pts_away) <= 15 ~ "Moderate", 
      TRUE ~ "Blowout"
    ) |> factor() |> fct_relevel("Close", "Moderate", "Blowout"),
    era = case_when(
      game_year < 1970 ~ "Early NBA",
      game_year < 2000 ~ "Classic Era",
      TRUE ~ "Modern"
    ) |> factor() |> fct_relevel("Early NBA", "Classic Era", "Modern"),
    month_start = floor_date(game_date, "month"),
    days_since_jan1 = as.numeric(game_date - floor_date(game_date, "year")),
    next_week = game_date + days(7)
  ) |>
  arrange(game_date) |>
  slice_head(n = 1000) |> 
  count(era, margin_category) |> 
  print()
```

###


### Exercise 9

Ask AI to use `data/game.parquet` and `data/line_score.parquet` and join them together by `game_id` using `left_join()` and parses `game_date` and `game_date_est` as `datetimes` in one singular pipe without creating intermediate variables. Make sure the `relationship` is set to `many-to-many` and `NA` values are dropped using `drop_na()`. 

Add this code as a replacement to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-9-test, echo = TRUE}
open_dataset("data/game.parquet") |>
  collect() |>
  left_join(
    open_dataset("data/line_score.parquet") |> collect(),
    by = "game_id",
    relationship = "many-to-many"
  ) |>
  mutate(
    game_date = ymd_hms(game_date),
    game_date_est = ymd_hms(game_date_est)
  ) |>
  drop_na(pts_home.x)
```

###

### Exercise 10

Ask AI to write R code that continues your pipe and uses `mutate()` to create three new columns: one called `game_date` by converting the existing `game_date` column with the `as_datetime` function, one called `game_year` by extracting the `year` from `game_date` with the `year()` function, and one called `season_label` by combining parts of `season_id` with the `paste0()` and `str_sub()` functions. Then ask it to use the `filter()` function to remove rows where `game_date` is missing and to keep only rows where `game_year` is greater than or equal to 1946.

Add this code as a continuation to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-10-test, echo = TRUE}
open_dataset("data/game.parquet") |>
  collect() |>
  left_join(
    open_dataset("data/line_score.parquet") |> collect(),
    by = "game_id",
    relationship = "many-to-many"
  ) |>
  mutate(
    game_date = ymd_hms(game_date),
    game_date_est = ymd_hms(game_date_est)
  ) |>
  drop_na(pts_home.x)|>
	mutate(
    game_date = as_datetime(game_date),
    game_year = year(game_date),
    season_label = paste0(season_id %/% 10000, "-", str_sub(season_id + 1, 3, 4))
  ) %>%
  filter(!is.na(game_date), game_year >= 1946)
```

###

### Exercise 11

Ask AI to write R code that continues your pipe and uses `mutate()` to convert the `wl_home` column into a factor with levels `W` and `L` so that home wins and losses are treated as categorical data, and to create a new column `game_era` using `case_when()` based on the `game_year` column so that each game is classified into "Pre-Three Point", "Modern Era", "Analytics Era", or "Current Era", and then convert `game_era` into a factor with these same levels to preserve the logical order.

Add this code as a continuation to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-11-test, echo = TRUE}
open_dataset("data/game.parquet") |>
  collect() |>
  left_join(
    open_dataset("data/line_score.parquet") |> collect(),
    by = "game_id",
    relationship = "many-to-many"
  ) |>
  mutate(
    game_date = ymd_hms(game_date),
    game_date_est = ymd_hms(game_date_est)
  ) |>
  drop_na(pts_home.x)|>
	mutate(
    game_date = as_datetime(game_date),
    game_year = year(game_date),
    season_label = paste0(season_id %/% 10000, "-", str_sub(season_id + 1, 3, 4))
  ) %>%
  filter(!is.na(game_date), game_year >= 1946) %>%
	mutate(
	wl_home = factor(wl_home, levels = c("W", "L")),
    game_era = case_when(
      game_year <= 1979 ~ "Pre-Three Point",
      game_year <= 1999 ~ "Modern Era", 
      game_year <= 2019 ~ "Analytics Era",
      TRUE ~ "Current Era"
    ),
    game_era = factor(game_era, levels = c("Pre-Three Point", "Modern Era", "Analytics Era", "Current Era"))
  ) 
```

###

### Exercise 12

Ask AI to write R code that continues your piep and uses `mutate()` with `across()` to replace missing values with 0 for all columns containing `"pct"` and for the columns `pts_home.x` and `pts_away.x` so that `NA`s are handled. Then, use `mutate()` again to create a new column `total_points` as the sum of `pts_home.x` and `pts_away.x`. Finally, use `filter()` to keep only rows where `total_points` is greater than 0 and neither `pts_home.x` nor `pts_away.x` are `NA`.

Add this code as a continuation to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-12-test, echo = TRUE}
open_dataset("data/game.parquet") |>
  collect() |>
  left_join(
    open_dataset("data/line_score.parquet") |> collect(),
    by = "game_id",
    relationship = "many-to-many"
  ) |>
  mutate(
    game_date = ymd_hms(game_date),
    game_date_est = ymd_hms(game_date_est)
  ) |>
  drop_na(pts_home.x)|>
	mutate(
    game_date = as_datetime(game_date),
    game_year = year(game_date),
    season_label = paste0(season_id %/% 10000, "-", str_sub(season_id + 1, 3, 4))
  ) %>%
  filter(!is.na(game_date), game_year >= 1946) %>%
	mutate(
	wl_home = factor(wl_home, levels = c("W", "L")),
    game_era = case_when(
      game_year <= 1979 ~ "Pre-Three Point",
      game_year <= 1999 ~ "Modern Era", 
      game_year <= 2019 ~ "Analytics Era",
      TRUE ~ "Current Era"
    ),
    game_era = factor(game_era, levels = c("Pre-Three Point", "Modern Era", "Analytics Era", "Current Era"))
  ) |>	
	mutate(
    	across(contains("pct"), ~replace_na(.x, 0)),
    	across(c(pts_home.x, pts_away.x), ~replace_na(.x, 0)),
    	total_points = pts_home.x + pts_away.x
 	 ) %>%
 	 filter(total_points > 0, !is.na(pts_home.x), !is.na(pts_away.x))
```

###

### Exercise 13

Ask AI to continue your pipe and write R code that uses `group_by()` to group the data by `game_year`, `game_era`, and `season_label`, then uses `summarise()` to calculate `avg_points` as the mean of `total_points`, `games_count` as the number of games, and `home_win_pct` as the mean of `wl_home` being `"W"` while removing NAs, and finally uses `arrange()` to sort the results by `game_year`.

Add this code as a continuation to your current code in the same code chunk in the same QMD.

Place your cursor at the beginning of the line where it says `data/game.parquet` and run `Cmd/Ctrl + Enter`.

CP/CR.

```{r nba-games-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

```{r nba-games-13-test, echo = TRUE}
open_dataset("data/game.parquet") |>
  collect() |>
  left_join(
    open_dataset("data/line_score.parquet") |> collect(),
    by = "game_id",
    relationship = "many-to-many"
  ) |>
  mutate(
    game_date = ymd_hms(game_date),
    game_date_est = ymd_hms(game_date_est)
  ) |>
  drop_na(pts_home.x)|>
	mutate(
    game_date = as_datetime(game_date),
    game_year = year(game_date),
    season_label = paste0(season_id %/% 10000, "-", str_sub(season_id + 1, 3, 4))
  ) %>%
  filter(!is.na(game_date), game_year >= 1946) %>%
	mutate(
	wl_home = factor(wl_home, levels = c("W", "L")),
    game_era = case_when(
      game_year <= 1979 ~ "Pre-Three Point",
      game_year <= 1999 ~ "Modern Era", 
      game_year <= 2019 ~ "Analytics Era",
      TRUE ~ "Current Era"
    ),
    game_era = factor(game_era, levels = c("Pre-Three Point", "Modern Era", "Analytics Era", "Current Era"))
  ) |>	
	mutate(
    	across(contains("pct"), ~replace_na(.x, 0)),
    	across(c(pts_home.x, pts_away.x), ~replace_na(.x, 0)),
    	total_points = pts_home.x + pts_away.x
 	 ) %>%
 	 filter(total_points > 0, !is.na(pts_home.x), !is.na(pts_away.x))|>
  group_by(game_year, game_era, season_label) %>%
  summarise(
    avg_points = mean(total_points, na.rm = TRUE),
    games_count = n(),
    home_win_pct = mean(wl_home == "W", na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(game_year)
```

###

### Exercise 14

Before creating a plot, we need to ensure that your data matches our data. In the QMD, replace your code from the previous exercise with our code.

In the Console, run:

```         
show_file("analysis.qmd", chunk = "Last")
```

CP/CR.

```{r nba-games-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

###

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 15

Within the latest code chunk, add the option: `#| cache: true`. Assign the result of the pipe to `nba_clean`. 

`Cmd/Ctrl + Shift + K`. By including `#| cache: true` you cause Quarto to cache the results of the chunk. The next time you render your QMD, as long as you have not changed the code, Quarto will just load up the saved object.

If you have not done so already, you should add `analysis_cache` to the `.gitginore`. The content of the cache file does not belong on GitHub.

Place your cursor on the line where the pipe is assigned to `nba_clean`, run `Cmd/Ctrl + Enter`, thus ensuring that the workspace also includes a copy of `nba_clean`.

CP/CR.

```{r nba-games-15}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    rows = 8)
```

###

Our code:

```{r, echo = TRUE}
nba_clean <- open_dataset("data/game.parquet") |>
  collect() |>
  left_join(
    open_dataset("data/line_score.parquet") |> collect(),
    by = "game_id",
    relationship = "many-to-many"
  ) |>
  mutate(
    game_date = ymd_hms(game_date),
    game_date_est = ymd_hms(game_date_est)
  ) |>
  drop_na(pts_home.x)|>
	mutate(
    game_date = as_datetime(game_date),
    game_year = year(game_date),
    season_label = paste0(season_id %/% 10000, "-", str_sub(season_id + 1, 3, 4))
  ) %>%
  filter(!is.na(game_date), game_year >= 1946) %>%
	mutate(
	wl_home = factor(wl_home, levels = c("W", "L")),
    game_era = case_when(
      game_year <= 1979 ~ "Pre-Three Point",
      game_year <= 1999 ~ "Modern Era", 
      game_year <= 2019 ~ "Analytics Era",
      TRUE ~ "Current Era"
    ),
    game_era = factor(game_era, levels = c("Pre-Three Point", "Modern Era", "Analytics Era", "Current Era"))
  ) |>	
	mutate(
    	across(contains("pct"), ~replace_na(.x, 0)),
    	across(c(pts_home.x, pts_away.x), ~replace_na(.x, 0)),
    	total_points = pts_home.x + pts_away.x
 	 ) %>%
 	 filter(total_points > 0, !is.na(pts_home.x), !is.na(pts_away.x))|>
  group_by(game_year, game_era, season_label) %>%
  summarise(
    avg_points = mean(total_points, na.rm = TRUE),
    games_count = n(),
    home_win_pct = mean(wl_home == "W", na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(game_year)
```

###

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 16

Within the Console, type `nba_clean`, which we previously assigned to a pipe and ran in the Console. Hit `Enter`.

CP/CR.

```{r nba-games-16}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    rows = 8)
```

###

Our code:

```{r, echo=TRUE}
nba_clean
```

###

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 17

Ask AI to generate R code that uses `nba_clean` to create a time series plot showing how `avg_points` changes across `game_year` for each `game_era`. Mention that you want to use the data from `nba_clean` and include the top 3 rows of the tibble (just enough to show the column names `game_year`, `avg_points`, `games_count`, and `game_era`) copied from the console. The code should use `ggplot()` with `geom_line()` and `geom_point()` (sized by `games_count`), apply a `viridis` color scale, label the axes and title, use `theme_minimal()`, and then convert the plot to an interactive `plotly` graph with tooltips for `x`, `y`, `colour`, and `size`.

Within `labs()`, edit or add a proper title, subtitle, and caption. If axis labels would be useful, add them, but if unnecessary, don't bother. Don't assign the code for the plot to any variable. Put the plot code in a new code chunk. Run `Cmd/Ctrl + Shift + K` to ensure that everything works. Make your plot look nice.

In the Console, run:

```         
show_file("analysis.qmd", chunk = "Last")
```

CP/CR.

```{r nba-games-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 12)
```

###

Our code:

```{r, echo=TRUE}
time_series_plot <- nba_clean %>%
  ggplot(aes(x = game_year, y = avg_points, color = game_era)) +
  geom_line(linewidth = 1.2, alpha = 0.8) +
  geom_point(aes(size = games_count),
             alpha = 0.7) +
  scale_color_viridis_d(option = "plasma") +
  scale_size_continuous(range = c(2, 6), guide = "none") +
  labs(
    title = "NBA Scoring Evolution: 75+ Years of Basketball",
    subtitle = "Average points per game by season with era classifications",
    x = "Season Year",
    y = "Average Points Per Game",
    color = "NBA Era"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white", color = NA)
  )

ggplotly(time_series_plot, 
                             tooltip = c("x", "y", "colour", "size")) %>%
  layout(
    hovermode = "closest",
    showlegend = TRUE,
    legend = list(orientation = "h", x = 0.1, y = -0.2),
    margin = list(b = 100, t = 80, l = 60, r = 40),
    hoverlabel = list(
      bgcolor = "white",
      bordercolor = "gray",
      font = list(family = "Arial", size = 12)
    )
  ) %>%
  config(displayModeBar = TRUE, displaylogo = FALSE)
```

###

<!-- XX: Make sure your plotting code is good! This will take some time. You had better have a subtitle which provides the take-away message of the plot. AI sometimes gives you too much code, lots of `theme()` stuff and so on. This is no good! In most cases, we are happy with concise, straightforward code. Insert a knowledge drop related to this project. -->

##
###

## Summary
###

<!-- XX: The exact same two to four sentence about the main packages/functions used in the Introduction, but written here in the past tense. You made a promise and you kept it.  -->

### Exercise 1

`Cmd/Ctrl + Shift + K` to ensure that everything works.  The resulting HTML page should be attractive, showing clean versions of your plots.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r summary-1}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 30)
```

### 

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 2

Publish your rendered QMD to GitHub Pages. In the Terminal --- not the Console! --- run:

````
quarto publish gh-pages XX.qmd
````

Copy/paste the resulting URL below.

```{r summary-2}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 1)
```

### 

<!-- XX: Insert a knowledge drop related to this project. -->

### Exercise 3

Commit and push all your files. Copy/paste the URL to your Github repo.

```{r summary-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX: The tutorial is now over. Add any necessary acknowledgements and/or provide a link to further high quality readings, ideally readings which you mentioned in at least one knowledge drop above. -->

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
